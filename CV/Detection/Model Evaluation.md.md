## 平均精度均值（mean Average Precision, mAP）
目标检测领域衡量模型综合性能最核心、最通用的指标
### TP、FP、FN
1. 真正例 (TP)：一个预测框与某个真实框的IoU > 阈值，并且类别也预测正确。
2. 假正例 (FP)：一个预测框不满足TP的条件。具体情况包括：\
（1）与所有真实框的 IoU 都 < 阈值（定位错误）。\
（2）定位正确（IoU > 阈值），但类别预测错误（分类错误）。\
（3）重复检测同一个真实框（多余的检测）。
3. 假反例 (FN)：漏检，一个真实框，模型没有预测出任何一个满足 IoU 阈值的边界框来覆盖它。
### P-R
1. 模型会对一张图片（或整个数据集）输出所有的预测框，每个框都有一个置信度分数
2. 将所有预测框从高到低按置信度分数进行排序
3. 逐个计算P和R：从首预测框开始，逐个将其“激活”，并把这个点之前的预测都看作是正例
4. 将计算出的 (Recall, Precision) 对作为坐标点，在二维坐标系中绘制出来，就形成了P-R曲线
### 平均精度 (Average Precision, AP)
1. 就是P-R曲线下的面积 (Area Under Curve, AUC)
2. 在实践中，我们通常不直接计算积分，而是采用插值的方法来近似计算面积
### mAP
上面计算的 AP 是针对单个类别的，需对所有类别求平均
## mAP@0.5 vs COCO mAP
主要区别在于IoU阈值的设定
### mAP@0.5 (或 AP50)
1. PASCAL VOC竞赛中使用的标准，相对宽松，主要衡量模型能否“大致”定位到物体
2. 在计算AP时，IoU阈值被固定为0.5
### COCO mAP (或 mAP@[.5:.05:.95])
1. 目前更常用、更严格的评估标准，由 COCO 数据集推广
2. 在多个IoU阈值下分别计算mAP，然后取平均值
3. 具体来说，IoU阈值从 0.5 开始，以 0.05 为步长，一直增加到 0.95（共 10 个）