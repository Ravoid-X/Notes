最常见的数据集划分方式是分为三部分：训练集 (Training Set)、验证集 (Validation Set) 和测试集 (Test Set)。
### 训练集
用于训练模型，即通过学习数据中的特征和模式来调整模型的参数（权重和偏置）
### 验证集
用于在训练过程中评估模型性能和调整超参数
### 测试集
用于最终评估模型的性能。它是在模型训练和超参数调整完成后，对模型性能的一次公平、客观的评估。
### 划分
1. 没有一个固定的比例，但一个常见的经验法则是训练集：60%-80%，验证集：10%-20%，测试集：10%-20%
2. 确保数据集的划分是随机的，如果数据有特定的顺序（例如按时间排序），需要打乱数据后再划分，以确保每个子集都具有相似的特征分布。
3. 对于分类任务，尤其是类别分布不平衡时，建议使用分层抽样。这可以确保每个子集中的类别比例与原始数据集中的比例保持一致。
4. 严禁在模型训练或超参数调整中使用任何测试集的信息
### 交叉验证
如果数据集比较小，划分出独立的验证集可能会导致训练集过小，模型无法充分学习。在这种情况下，交叉验证是一种更好的选择。
1. K-折交叉验证 (K-Fold Cross-Validation)：将训练集分成 K 个大小相等的子集（折）。在每次迭代中，选择其中一个子集作为验证集，其余 K−1 个子集作为训练集。这个过程重复 K 次，每次都使用不同的子集作为验证集。最后，将 K 次的结果取平均值作为模型的最终性能评估。
2. 优点：充分利用了数据，能够更稳定地评估模型性能。
3. 缺点：计算成本更高，尤其是在大数据集上。