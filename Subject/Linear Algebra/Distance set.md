1. 曼哈顿距离：两个点在标准坐标系上的绝对轴距之和\
$d(x,y)=\sum ^n _{i=1}|x_i-y_i|$
2. 欧式距离（L2范数）：欧氏空间中两点之间的真实距离\
$d(x,y)=\sqrt {\sum ^n _{i=1}(x_i-y_i)^2}$
3. 切比雪夫距离（Chebyshev）:各坐标数值差绝对值的最大值，也称无穷范数\
$d(x,y)=max(|x_1-y_1|,|x_2-y_2|)$
4. 闵可夫斯基距离（Minkowski）：从严格意义上讲，其不是一种距离，而是一组距离的定义。\
$d(x,y)=(\sum ^n _{i=1}|x_i-y_i|^p)^{\frac 1 p}$\
p=1时，为曼哈顿距离\
p=2时，为欧氏距离\
p=3时，为切比雪夫距离
5. 汉明距离：两个字符串对应位置的不同字符的个数\
例：101 与 100 之间的汉明距离是 1
6. 余弦相似性（夹角余弦）：评估向量相似度，取值范围为 [-1,1]，当两个向量方向重合时，取1；当两个向量方向相反时，取-1\
$cos(θ)=\frac {\sum ^n _{i=1}A_i \times B_i} {\sqrt{\sum ^n _{i=1}(A_i)^2}\times\sqrt{\sum ^n _{i=1}(B_i)^2}}$
7. 杰卡德相似系数（Jaccard）：用于比较有限样本集之间的相似性与差异性，值越大，样本相似度越高。定义为A与B交集的大小与A与B并集的大小的比值。\
$J(A,B)=\frac {|A∩B|} {|A∪B|}$\
当集合 $A$，$B$ 都为空时，$J(A,B)$ 定义为1
8. 杰卡德距离：用于描述集合之间的不相似度。距离越大，样本相似度越低。\
$d_j(A,B)=1-J(A,B)$\
（1）比较文本相似度，用于文本查重与去重。\
（2）计算对象间距离，用于数据聚类等。\
（3）推荐系统。杰卡德方法在基于物品的协同过滤系统中建立评价分析方法，完善了余弦相似性只考虑用户评分而忽略了其他信息量的弊端，特别适合于稀疏度过高的数据。
9. 马氏距离（Mahalanobis）：表示数据的协方差距离，是一种有效的计算两个未知样本集的相似度的方法。考虑到数据特征之间的联系，并且是尺度无关的（scale-invariant）。\
假设 $x,y$ 是从均值向量为 $μ$，协方差矩阵为 $\sum$ 的总体 $G$中随机抽取的两个样本\
$x,y$ 马氏距离：$d^2_m(x,y)=(x-y)^T\sum ^{-1}(x-y)$\
$x,G$ 马氏距离：$d^2_m(x,μG)=(x-μG)^T\sum ^{-1}(x-μG)$\
如果协方差矩阵是单位向量，也就是各维度独立同分布，马氏距离就变成了欧氏距离。